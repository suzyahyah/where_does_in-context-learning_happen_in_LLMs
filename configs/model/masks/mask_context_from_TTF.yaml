model:
    cuda: True
    model_size: gptn2.7B
    hack: True
    save_fol: ""
    mask_from: True
    mask_layer: 0
    causal_mask:
        instructions: True
        prompts: True
        query: False
