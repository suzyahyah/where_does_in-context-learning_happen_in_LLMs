{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3015523-c759-4e5b-ac1e-468dc7e202ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/where_does_in-context-learning_happen_in_LLMs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "#%cd $HOME/projects/where_does_icl_happen\n",
    "%cd /workspace/where_does_in-context-learning_happen_in_LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e63fa91-8988-456f-b0a7-319e5f69ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm > /dev/null 2>&1\n",
    "!pip install omegaconf > /dev/null 2>&1\n",
    "!pip install seaborn > /dev/null 2>&1\n",
    "!pip install pynvml > /dev/null 2>&1\n",
    "!pip install transformers > /dev/null 2>&1\n",
    "!pip install sacrebleu > /dev/null 2>&1\n",
    "!pip install nltk  > /dev/null 2>&1\n",
    "!pip install accelerate > /dev/null 2>&1\n",
    "!pip install -U bitsandbytes > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4516fca6-a4a5-461b-884a-e097736f5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import utils, build, io_utils\n",
    "from src.datasets.collate_fn import CollateFn\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "985fe33b-0735-4bef-8d9e-bdc40e9495e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_HOME'] = \"/workspace/.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778a64f-4388-4241-a077-9b0ba870d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model class: GPTNeoForCausalLMHack\n"
     ]
    }
   ],
   "source": [
    "args_model = OmegaConf.load('configs/model/masks/mask_context_from_TTF.yaml')\n",
    "args_data = OmegaConf.load('configs/data/default.yaml')\n",
    "args_format = OmegaConf.load('configs/format/instr_machine_translation.yaml')\n",
    "args_model.model.model_size=\"gptn125M\"\n",
    "model, tokenizer = build.build_model_tok(args_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4759b-7c1c-453b-8f3e-d4a618b308ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.prompt_dataset import PromptsDataset\n",
    "promptbank, test_dataset = build.build_datasets_for_prompt(args_data.data)\n",
    "prompt_ds = PromptsDataset(args_format.format, \n",
    "                           promptbank,\n",
    "                           test_dataset,\n",
    "                           seed=0, \n",
    "                           nprompts=1,\n",
    "                           ntest=1)\n",
    "collate_fn = CollateFn(tokenizer)\n",
    "dataloader = DataLoader(prompt_ds, collate_fn=collate_fn, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ca76b6d-0c00-450f-ac01-d2bf22714bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reset_mask(model)\n",
    "args_model.model.mask_layer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c88d0b2-80f1-4a49-ac43-8fe8740aca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import build_causal_mask_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d7ce0-5a2e-424a-b2c6-7326fd11f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for j, batch in enumerate(tqdm(dataloader)):        \n",
    "        build_causal_mask_per_batch(args_model.model, model, batch)    \n",
    "        outputs_w_mask = model.generate(batch['input_ids'],\n",
    "                                 attention_mask=batch['attention_mask'],\n",
    "                                 pad_token_id=tokenizer.pad_token_id,\n",
    "                                 output_attentions=True,\n",
    "                                 return_dict_in_generate=True,\n",
    "                                 output_scores=True)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d85b2-22b4-40db-b9a7-1d587ce6c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_attn = outputs_w_mask['attentions'][0][0][0][0]\n",
    "sns.heatmap(out_attn.cpu().numpy(), cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581eaa00-5487-4e28-8dc5-1b01b4decaf4",
   "metadata": {},
   "source": [
    "Illustration of redundancy in self-attention computation based on our masking\n",
    "setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c53ccf-e2e1-459e-a866-5aa814cbcec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
